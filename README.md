![goLLM Logo](gollm.svg)

# goLLM - Go Learn, Lead, Master!

[![PyPI Version](https://img.shields.io/pypi/v/gollm?style=for-the-badge&logo=pypi&logoColor=white&label=version)](https://pypi.org/project/gollm/)
[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg?style=for-the-badge)](https://opensource.org/licenses/Apache-2.0)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg?style=for-the-badge)](https://github.com/psf/black)
[![Tests](https://img.shields.io/badge/tests-passing-brightgreen?style=for-the-badge&logo=github-actions&logoColor=white)](https://github.com/wronai/gollm/actions)
[![Documentation](https://img.shields.io/badge/docs-latest-brightgreen?style=for-the-badge&logo=read-the-docs&logoColor=white)](https://gollm.readthedocs.io)

> **Dlaczego goLLM?** - Bo wierzymy, Å¼e jakoÅ›Ä‡ kodu to nie luksus, a standard. goLLM to wiÄ™cej niÅ¼ narzÄ™dzie - to twÃ³j asystent w dÄ…Å¼eniu do doskonaÅ‚oÅ›ci programistycznej.

## ğŸš€ O projekcie

goLLM to zaawansowany system kontroli jakoÅ›ci kodu Python zintegrowany z modelami jÄ™zykowymi (LLM), ktÃ³ry przeksztaÅ‚ca proces programowania w pÅ‚ynne doÅ›wiadczenie, gdzie jakoÅ›Ä‡ kodu jest gwarantowana od pierwszego znaku.

### Kluczowe wartoÅ›ci:
- **Nauka przez praktykÄ™** - Automatyczne sugestie i wyjaÅ›nienia poprawiajÄ…ce TwÃ³j kod
- **PrzywÃ³dztwo w jakoÅ›ci** - Ustanawiamy najwyÅ¼sze standardy w projektach
- **Mistrzostwo w automatyzacji** - Inteligentne narzÄ™dzia, ktÃ³re pracujÄ… dla Ciebie

## ğŸ’« Funkcje

- ğŸ”¥ **Generowanie kodu z LLM** - Tworzenie kodu na podstawie opisu w jÄ™zyku naturalnym
- ğŸ” **Walidacja kodu** - Automatyczne sprawdzanie jakoÅ›ci i poprawnoÅ›ci kodu
- ğŸ“ˆ **Metryki jakoÅ›ci** - Åšledzenie postÄ™pÃ³w i trendÃ³w jakoÅ›ci kodu
- ğŸ“ **ZarzÄ…dzanie TODO** - Automatyczne Å›ledzenie zadaÅ„ i problemÃ³w
- ğŸ’¬ **WyjaÅ›nienia kodu** - ZrozumiaÅ‚e komentarze i dokumentacja
- ğŸ‘· **Automatyczne naprawy** - Inteligentne poprawki bÅ‚Ä™dÃ³w i problemÃ³w
- ğŸš€ **Streaming odpowiedzi** - Szybsze generowanie kodu z modularnym adapterem Ollama

## ğŸ“š Dokumentacja

### ğŸ“– Przewodniki
- [Wprowadzenie](./docs/guides/getting_started.md) - Pierwsze kroki z goLLM
- [Konfiguracja projektu](./docs/configuration/README.md) - SzczegÃ³Å‚y konfiguracji
- [Integracja z Ollama](./docs/guides/ollama_setup.md) - Jak uÅ¼ywaÄ‡ lokalnych modeli LLM
- [Generowanie wielu plikÃ³w](./docs/guides/multi_file_generation.md) - ZarzÄ…dzanie zÅ‚oÅ¼onymi projektami
- [Streaming odpowiedzi](./docs/guides/streaming.md) - Szybsze generowanie kodu z modularnym adapterem

### ğŸ› ï¸ API
- [Podstawowe funkcje](./docs/api/core.md) - GÅ‚Ã³wne komponenty goLLM
- [Rozszerzenia](./docs/api/extensions.md) - Jak rozszerzaÄ‡ funkcjonalnoÅ›Ä‡
- [Interfejs wiersza poleceÅ„](./docs/api/cli.md) - PeÅ‚na dokumentacja CLI

### âš™ï¸ Konfiguracja
- [Zaawansowane opcje](./docs/configuration/advanced.md) - SzczegÃ³Å‚owa konfiguracja
- [ReguÅ‚y walidacji](./docs/configuration/validation_rules.md) - Dostosowywanie zasad jakoÅ›ci kodu
- [Integracja z LLM](./docs/configuration/llm_integration.md) - Konfiguracja modeli jÄ™zykowych
- [ZarzÄ…dzanie projektem](./docs/configuration/project_management.md) - Automatyzacja zadaÅ„

## ğŸš€ Szybki start

### Wymagania wstÄ™pne
- Python 3.8+
- pip (najnowsza wersja)
- Ollama (opcjonalnie, dla lokalnych modeli LLM)

### Instalacja

```bash
# Podstawowa instalacja
pip install gollm

# Z obsÅ‚ugÄ… LLM (zalecane)
pip install gollm[llm]

# Lub dla deweloperÃ³w
git clone https://github.com/wronai/gollm.git
cd gollm
pip install -e .[dev]
```

### Pierwsze kroki

1. **Skonfiguruj projekt**
   ```bash
   # PrzejdÅº do katalogu projektu
   cd twÃ³j_projekt
   
   # Zainicjuj konfiguracjÄ™ (tworzy plik gollm.json)
   gollm init
   ```
   
   > â„¹ufe0f WiÄ™cej o konfiguracji: [Dokumentacja konfiguracji](./docs/configuration/README.md)

2. **Uruchom analizÄ™ kodu**
   ```bash
   # SprawdÅº pojedynczy plik
   gollm validate plik.py
   
   # SprawdÅº caÅ‚y projekt
   gollm validate-project
   
   # SprawdÅº status projektu
   gollm status
   
   # PokaÅ¼ metryki jakoÅ›ci kodu
   gollm metrics
   
   # PokaÅ¼ trendy jakoÅ›ci kodu
   gollm trend --period month
   ```

3. **Generuj kod z LLM**
   ```bash
   # Standardowe generowanie z walidacjÄ…
   gollm generate "StwÃ³rz klasÄ™ uÅ¼ytkownika"
   
   # Szybkie generowanie (tryb fast)
   gollm generate "StwÃ³rz klasÄ™ uÅ¼ytkownika" --fast
   
   # BezpoÅ›redni dostÄ™p do API (bez walidacji)
   gollm direct generate "StwÃ³rz klasÄ™ uÅ¼ytkownika"
   
   # BezpoÅ›redni dostÄ™p do API w trybie czatu
   gollm direct chat "Jak zaimplementowaÄ‡ klasÄ™ uÅ¼ytkownika?"
   
   # UÅ¼yj modularnego adaptera z obsÅ‚ugÄ… streamingu dla lepszej wydajnoÅ›ci
   gollm generate "StwÃ³rz klasÄ™ uÅ¼ytkownika" --adapter-type modular --use-streaming
   ```
   
   > ğŸ“˜ PeÅ‚na dokumentacja dostÄ™pna w [przewodniku wprowadzajÄ…cym](./docs/guides/getting_started.md)

## ğŸ¯ PrzykÅ‚ad w dziaÅ‚aniu

PoniÅ¼ej przedstawiamy prosty przykÅ‚ad, jak goLLM moÅ¼e pomÃ³c w ulepszeniu jakoÅ›ci kodu. WiÄ™cej przykÅ‚adÃ³w i szczegÃ³Å‚Ã³w znajdziesz w [dokumentacji API](./docs/api/core.md).

```python
# Przed uÅ¼yciem goLLM
def process_data(x):
    # ... zÅ‚oÅ¼ona logika bez dokumentacji ...
    pass

# Po uÅ¼yciu goLLM
def process_data(data: List[Dict]) -> Dict[str, Any]:
    """Przetwarza dane wejÅ›ciowe zgodnie z wymaganiami biznesowymi.
    
    Args:
        data: Lista sÅ‚ownikÃ³w zawierajÄ…cych dane do przetworzenia
        
    Returns:
        SÅ‚ownik zawierajÄ…cy wyniki przetwarzania
        
    Raises:
        ValueError: Gdy dane wejÅ›ciowe sÄ… nieprawidÅ‚owe
    """
    # ... czytelna i udokumentowana implementacja ...
    pass
```

> ğŸ“˜ Zobacz wiÄ™cej przykÅ‚adÃ³w w [przewodniku wprowadzajÄ…cym](./docs/guides/getting_started.md#przykÅ‚ady) i [dokumentacji API](./docs/api/README.md).
            bool(user_data.preferences)
        )
    
    def _process_user_data(self, user_data: UserData) -> None:
        """Wykonuje wÅ‚aÅ›ciwe przetwarzanie danych uÅ¼ytkownika."""
        # Tutaj nastÄ™puje logika przetwarzania
        pass
```

## ğŸ“Š KorzyÅ›ci z uÅ¼ywania goLLM

### Dla programistÃ³w
- **OszczÄ™dnoÅ›Ä‡ czasu** - Automatyczne poprawki i sugestie
- **Nauka najlepszych praktyk** - Natychmiastowy feedback jakoÅ›ci kodu
- **Mniejsze obciÄ…Å¼enie code review** - Mniej bÅ‚Ä™dÃ³w trafia do recenzji

### Dla zespoÅ‚Ã³w
- **SpÃ³jnoÅ›Ä‡ kodu** - Jednolite standardy w caÅ‚ym projekcie
- **Åatwiejsze wdraÅ¼anie nowych czÅ‚onkÃ³w** - Automatyczne egzekwowanie standardÃ³w
- **Lepsza jakoÅ›Ä‡ kodu** - Systematyczne eliminowanie antywzorcÃ³w

### Dla firmy
- **NiÅ¼sze koszty utrzymania** - Lepsza jakoÅ›Ä‡ kodu = mniej bugÃ³w
- **Szybsze wdraÅ¼anie** - Zautomatyzowane procesy kontroli jakoÅ›ci
- **WiÄ™ksza wydajnoÅ›Ä‡ zespoÅ‚u** - Mniej czasu na poprawki, wiÄ™cej na rozwÃ³j

## ğŸ”„ Jak to dziaÅ‚a?

goLLM dziaÅ‚a w oparciu o zaawansowany system analizy kodu, ktÃ³ry Å‚Ä…czy w sobie:

1. **StatycznÄ… analizÄ™ kodu** - Wykrywanie potencjalnych bÅ‚Ä™dÃ³w i antywzorcÃ³w
2. **DynamicznÄ… analizÄ™** - Åšledzenie wykonania kodu w czasie rzeczywistym
3. **IntegracjÄ™ z LLM** - Kontekstowe sugestie i automatyzacja zadaÅ„
4. **Automatyczne raportowanie** - Kompleksowe metryki jakoÅ›ci kodu

### PrzykÅ‚adowy workflow

```mermaid
graph TD
    A[Nowy kod] --> B{Analiza goLLM}
    B -->|BÅ‚Ä™dy| C[Automatyczne poprawki]
    B -->|OstrzeÅ¼enia| D[Sugestie ulepszeÅ„]
    B -->|Krytyczne| E[Blokada zapisu]
    C --> F[Ponowna analiza]
    D --> G[Recenzja programisty]
    F -->|OK| H[ZatwierdÅº zmiany]
    G -->|Zaakceptowano| H
    H --> I[Aktualizacja CHANGELOG]
    I --> J[Integracja z systemem CI/CD]
```

## âš™ï¸ Konfiguracja

goLLM oferuje elastycznÄ… konfiguracjÄ™ dopasowanÄ… do potrzeb Twojego projektu. Podstawowa konfiguracja znajduje siÄ™ w pliku `gollm.json`.

### PrzykÅ‚adowa konfiguracja

```json
{
  "version": "0.2.0",
  "validation_rules": {
    "max_function_lines": 50,
    "max_file_lines": 300,
    "max_cyclomatic_complexity": 10,
    "max_function_params": 5,
    "max_line_length": 88,
    "forbid_print_statements": true,
    "forbid_global_variables": true,
    "require_docstrings": true,
    "require_type_hints": false,
    "naming_convention": "snake_case"
  },
  "project_management": {
    "todo_integration": true,
    "auto_create_tasks": true,
    "changelog_integration": true
  },
  "llm_integration": {
    "enabled": true,
    "provider": "openai",
    "model": "gpt-4"
  }
}
```

### Integracja z narzÄ™dziami deweloperskimi

#### Integracja z NarzÄ™dziami

GoLLM moÅ¼na zintegrowaÄ‡ z istniejÄ…cymi narzÄ™dziami deweloperskimi poprzez konfiguracjÄ™ w pliku `gollm.json`. Aby uzyskaÄ‡ wiÄ™cej informacji, sprawdÅº dokumentacjÄ™ konfiguracji.

```bash
# SprawdÅº aktualnÄ… konfiguracjÄ™
gollm config list

# ZmieÅ„ ustawienia konfiguracji
gollm config set <klucz> <wartoÅ›Ä‡>
```

#### CI/CD
```yaml
# PrzykÅ‚ad dla GitHub Actions
name: goLLM Validation

on: [push, pull_request]

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    - name: Install goLLM
      run: pip install gollm[llm]
    - name: Run validation
      run: gollm validate .
```

## ğŸ“Š Metryki i analiza

goLLM dostarcza szczegÃ³Å‚owych metryk i analiz, ktÃ³re pomagajÄ… Å›ledziÄ‡ jakoÅ›Ä‡ kodu w czasie.

### DostÄ™pne komendy

#### Metryki jakoÅ›ci kodu
```bash
# PokaÅ¼ aktualne metryki jakoÅ›ci kodu
gollm metrics
```

#### Trendy jakoÅ›ci w czasie
```bash
# PokaÅ¼ trendy jakoÅ›ci kodu w okreÅ›lonym okresie
gollm trend --period month
```

#### Status projektu
```bash
# SprawdÅº aktualny status projektu i zdrowia kodu
gollm status
```

### PrzykÅ‚adowe metryki
- **JakoÅ›Ä‡ kodu** - Ocena 0-100%
- **Pokrycie testami** - Procent kodu objÄ™tego testami
- **ZÅ‚oÅ¼onoÅ›Ä‡ cyklomatyczna** - Åšrednia zÅ‚oÅ¼onoÅ›Ä‡ metod
- **DÅ‚ug techniczny** - Szacowany czas potrzebny na poprawÄ™ jakoÅ›ci

## ğŸ¤– Integracja z modelami jÄ™zykowymi

goLLM moÅ¼e wspÃ³Å‚pracowaÄ‡ z rÃ³Å¼nymi dostawcami modeli jÄ™zykowych:

### OpenAI GPT
```bash
export OPENAI_API_KEY="twÃ³j-klucz"
gollm config set llm.provider openai
gollm config set llm.model gpt-4
```

### Anthropic Claude
```bash
export ANTHROPIC_API_KEY="twÃ³j-klucz"
gollm config set llm.provider anthropic
gollm config set llm.model claude-3-opus
```

### Ollama (lokalny)
```bash
gollm config set llm.provider ollama
gollm config set llm.model codellama:13b
```

## ğŸŒ Wsparcie spoÅ‚ecznoÅ›ci

### Gdzie uzyskaÄ‡ pomoc?
- [Dokumentacja](https://gollm.readthedocs.io)
- [Issue Tracker](https://github.com/wronai/gollm/issues)
- [Dyskusje](https://github.com/wronai/gollm/discussions)
- [PrzykÅ‚ady uÅ¼ycia](https://github.com/wronai/gollm/examples)

### Jak moÅ¼esz pomÃ³c?
1. ZgÅ‚aszaj bÅ‚Ä™dy i propozycje funkcji
2. UdostÄ™pniaj przykÅ‚ady uÅ¼ycia
3. Pomagaj w tÅ‚umaczeniu dokumentacji
4. Rozwijaj projekt przez pull requesty

## ğŸ“œ Licencja

Projekt goLLM jest dostÄ™pny na licencji [Apache 2.0](LICENSE).

## ğŸ¤ Integracja z LLM Providers

### OpenAI
```bash
export OPENAI_API_KEY="sk-..."
gollm config set llm.provider openai
gollm config set llm.model gpt-4
```

### Anthropic Claude
```bash
export ANTHROPIC_API_KEY="sk-ant-..."
gollm config set llm.provider anthropic
gollm config set llm.model claude-3-sonnet
```

## ğŸ“š Dokumentacja

- [ğŸ“– Dokumentacja API](docs/api_reference.md)
- [âš™ï¸ Przewodnik Konfiguracji](docs/configuration.md)
- [ğŸ¤– Integracja z LLM](docs/llm_integration.md)
- [ğŸš€ Przewodnik WprowadzajÄ…cy](docs/getting_started.md)

## ğŸ¤ WkÅ‚ad w Projekt

```bash
# Sklonuj repozytorium
git clone https://github.com/wronai/gollm
cd gollm

# Zainstaluj dla deweloperÃ³w
pip install -e .[dev]

# Uruchom testy
pytest

# SprawdÅº jakoÅ›Ä‡ kodu
gollm validate-project
```

## ğŸ“„ Licencja

MIT License - zobacz [LICENSE](LICENSE) po szczegÃ³Å‚y.

## ğŸŒŸ Roadmapa

- [ ] **v0.2.0** - Integracja z wiÄ™cej IDE (PyCharm, Sublime)
- [ ] **v0.3.0** - ObsÅ‚uga JavaScript/TypeScript
- [ ] **v0.4.0** - Integracja z CI/CD (GitHub Actions, GitLab CI)
- [ ] **v0.5.0** - Dashboard webowy z metrykami zespoÅ‚u
- [ ] **v1.0.0** - Enterprise features + self-hosted LLM

---

**goLLM** - Gdzie jakoÅ›Ä‡ kodu spotyka siÄ™ z inteligencjÄ…! ğŸš€45-90 minutes
  - **Related Files:** `examples/bad_code.py:15`

- [ ] **CRITICAL: Function `process_user_data()` has cyclomatic complexity 12 (max: 10)**
  - **Created:** 2025-06-01 14:23:15
  - **Location:** `examples/bad_code.py:15`
  - **Suggested Fix:** Simplify logic or extract sub-functions
  - **Estimated Effort:** 1-3 hours

- [ ] **MAJOR: File `bad_code.py` exceeds maximum lines (150+ lines, max: 300)**
  - **Created:** 2025-06-01 14:23:15
  - **Impact:** Code maintainability
  - **Suggested Fix:** Split into smaller modules
  - **Estimated Effort:** 2-4 hours

## ğŸŸ¡ MEDIUM Priority

### Code Improvements
- [ ] **Replace print statements with logging (5 instances found)**
  - **Created:** 2025-06-01 14:23:15
  - **Files:** `examples/bad_code.py`
  - **Auto-fix Available:** âœ… Yes
  - **Command:** `gollm fix --rule print_statements examples/bad_code.py`
  - **Estimated Effort:** 


  # goLLM - Kompletna Implementacja Systemu

## ğŸ¯ Podsumowanie RozwiÄ…zania

**goLLM (Go Learn, Lead, Master!)** to kompletny system kontroli jakoÅ›ci kodu z integracjÄ… LLM, ktÃ³ry automatycznie:

1. **Waliduje kod w czasie rzeczywistym** - blokuje zapisywanie/wykonanie kodu niespeÅ‚niajÄ…cego standardÃ³w
2. **Integruje siÄ™ z LLM** - automatycznie poprawia kod przez AI z kontekstem projektu
3. **ZarzÄ…dza dokumentacjÄ… projektu** - automatycznie aktualizuje TODO i CHANGELOG
4. **Agreguje konfiguracje** - Å‚Ä…czy ustawienia z rÃ³Å¼nych narzÄ™dzi (flake8, black, mypy)


## ğŸš€ Kluczowe Komponenty

### 1. **Core Engine** (7 plikÃ³w)
- `GollmCore` - gÅ‚Ã³wna klasa orkiestrujÄ…ca
- `CodeValidator` - walidacja kodu z AST analysis
- `GollmConfig` - zarzÄ…dzanie konfiguracjÄ…
- `CLI` - interfejs wiersza poleceÅ„

### 2. **LLM Integration** (8 plikÃ³w)
- `LLMOrchestrator` - orkiestracja komunikacji z LLM
- `ContextBuilder` - budowanie kontekstu dla LLM
- `PromptFormatter` - formatowanie promptÃ³w
- `ResponseValidator` - walidacja odpowiedzi LLM

### 3. **Project Management** (6 plikÃ³w)
- `TodoManager` - automatyczne zarzÄ…dzanie TODO
- `ChangelogManager` - automatyczne aktualizacje CHANGELOG
- `TaskPrioritizer` - priorytetyzacja zadaÅ„

### 4. **Real-time Monitoring** (6 plikÃ³w)
- `LogAggregator` - agregacja logÃ³w wykonania
- `ExecutionMonitor` - monitoring procesÃ³w
- `LogParser` - parsowanie bÅ‚Ä™dÃ³w i traceback

### 5. **Configuration System** (7 plikÃ³w)
- `ProjectConfigAggregator` - agregacja konfiguracji
- Parsery dla: flake8, black, mypy, pyproject.toml
- Wykrywanie konfliktÃ³w miÄ™dzy narzÄ™dziami

## ğŸ¬ PrzykÅ‚ad Kompletnego Workflow

### Scenariusz: LLM generuje kod â†’ goLLM kontroluje jakoÅ›Ä‡

```bash
# 1. UÅ¼ytkownik prosi LLM o kod
$ gollm generate "Create a user authentication system"

# 2. LLM generuje kod (przykÅ‚ad z naruszeniami)
# Generated code has: 9 parameters, print statements, high complexity

# 3. goLLM automatycznie waliduje
ğŸ” goLLM: Validating generated code...
âŒ Found 4 violations:
   - Function has 9 parameters (max: 5)
   - Print statement detected
   - Cyclomatic complexity 12 (max: 10)
   - Missing docstring

# 4. goLLM wysyÅ‚a feedback do LLM
ğŸ¤– Sending violations to LLM for improvement...

# 5. LLM generuje poprawiony kod
âœ… Iteration 2: All violations resolved
ğŸ“ TODO updated: 0 new tasks (all fixed)
ğŸ“ CHANGELOG updated: Code generation entry added
ğŸ’¾ Code saved: user_auth.py
ğŸ“Š Quality score: 85 â†’ 92 (+7)

# 6. Automatyczne testy
ğŸ§ª Running validation on saved file...
âœ… All checks passed
ğŸš€ Ready for commit
```

### Automatyczne Aktualizacje Dokumentacji

**TODO.md** (automatycznie zarzÄ…dzane):
```markdown
# TODO List - Updated: 2025-06-01 14:23:15

## ğŸ”´ HIGH Priority (0 tasks)
âœ… All high priority issues resolved!

## ğŸŸ¡ MEDIUM Priority (2 tasks)
- [ ] Add unit tests for UserAuth class
- [ ] Add API documentation

## ğŸŸ¢ LOW Priority (1 task)
- [ ] Optimize password hashing performance
```

**CHANGELOG.md** (automatycznie aktualizowane):
```markdown
## [Unreleased] - 2025-06-01

### Added
- **[goLLM]** User authentication system with secure password handling
  - **File:** `user_auth.py`
  - **Quality Improvement:** +7 points
  - **LLM Generated:** âœ… Yes (2 iterations)

### Fixed  
- **[goLLM]** Resolved parameter count violation in authentication function
  - **Before:** 9 parameters
  - **After:** 2 parameters (using dataclass)
  - **Complexity Reduction:** 12 â†’ 4
```

## ğŸ› ï¸ Instalacja i Uruchomienie

### Szybka Instalacja
```bash
# Sklonuj/pobierz goLLM
curl -sSL https://raw.githubusercontent.com/wronai/gollm/main/install.sh | bash

# Lub rÄ™cznie
git clone https://github.com/wronai/gollm
cd gollm
./install.sh
```

### Demo
```bash
# Uruchom demonstracjÄ™
./run_demo.sh

# Lub na Windows
run_demo.bat
```

### Podstawowe Komendy
```bash
# Walidacja projektu
gollm validate-project

# Status jakoÅ›ci
gollm status

# NastÄ™pne zadanie TODO
gollm next-task

# Generowanie kodu z LLM
gollm generate "create payment processor"
gollm generate "create website simple with frontend, api and backend"

# Auto-poprawki
gollm fix --auto
```

## ğŸ”§ Konfiguracja

### Plik `gollm.json`
```json
{
  "validation_rules": {
    "max_function_lines": 50,
    "max_file_lines": 300,
    "forbid_print_statements": true,
    "require_docstrings": true
  },
  "llm_integration": {
    "enabled": true,
    "model_name": "gpt-4",
    "max_iterations": 3
  },
  "project_management": {
    "todo_integration": true,
    "changelog_integration": true
  }
}
```

### Integracja z IDE i NarzÄ™dziami

GoLLM moÅ¼na zintegrowaÄ‡ z IDE i narzÄ™dziami deweloperskimi poprzez konfiguracjÄ™ w pliku `gollm.json`.

```bash
# SprawdÅº aktualnÄ… konfiguracjÄ™
gollm config list

# ZmieÅ„ ustawienia konfiguracji
gollm config set <klucz> <wartoÅ›Ä‡>
```

MoÅ¼liwe integracje:
- Walidacja kodu w czasie rzeczywistym
- Automatyczne poprawki przy zapisie
- Sugestie LLM w edytorze
- Integracja z systemem kontroli wersji

## ğŸ“Š Metryki i Raportowanie

```bash
# PokaÅ¼ aktualne metryki jakoÅ›ci kodu
gollm metrics

# PokaÅ¼ trendy jakoÅ›ci kodu w okreÅ›lonym okresie
gollm trend --period month

# SprawdÅº status projektu i zdrowia kodu
gollm status

# PrzykÅ‚adowy wynik:
Quality Score: 89/100
Code Coverage: 78%
Cyclomatic Complexity: 2.4 (Good)
Technical Debt: 3.2 days
Violations Fixed: 47
LLM Iterations: 156 (avg 2.3 per request)
```

## ğŸ¯ Kluczowe KorzyÅ›ci

1. **Zero-config Quality Control** - dziaÅ‚a out-of-the-box
2. **LLM-Powered Fixes** - automatyczne poprawki przez AI
3. **Seamless Project Management** - TODO/CHANGELOG bez wysiÅ‚ku
4. **IDE Integration** - wsparcie dla popularnych edytorÃ³w
5. **Git Workflow** - automatyczne hooki i walidacja
6. **Extensible Architecture** - Å‚atwe dodawanie nowych reguÅ‚

## ğŸš€ Roadmapa

- **v0.2.0** - ObsÅ‚uga TypeScript/JavaScript
- **v0.3.0** - Web dashboard z metrykami zespoÅ‚u  
- **v0.4.0** - Integracja z CI/CD pipelines
- **v0.5.0** - Enterprise features + self-hosted LLM

---

**goLLM** to kompletne rozwiÄ…zanie, ktÃ³re Å‚Ä…czy kontrolÄ™ jakoÅ›ci kodu z mocÄ… LLM, tworzÄ…c inteligentny system wspomagajÄ…cy deweloperÃ³w w pisaniu lepszego kodu! ğŸâœ¨




## ğŸ—ï¸ **Architektura Systemu**

### Core Components (100% Complete)
1. **GollmCore** - GÅ‚Ã³wny orkiestrator
2. **CodeValidator** - Walidacja AST + reguÅ‚y jakoÅ›ci  
3. **LLMOrchestrator** - Integracja z AI (OpenAI/Anthropic/Ollama)
4. **TodoManager** - Automatyczne TODO z naruszeÅ„
5. **ChangelogManager** - Automatyczne CHANGELOG
6. **ConfigAggregator** - ÅÄ…czenie konfiguracji z rÃ³Å¼nych narzÄ™dzi
7. **GitAnalyzer** - Integracja z Git + hooks
8. **FileWatcher** - Monitoring zmian w czasie rzeczywistym

### Features (100% Implemented)
- âœ… **Real-time Code Validation** - Walidacja podczas pisania
- âœ… **LLM Integration** - OpenAI, Anthropic, Ollama
- âœ… **Auto TODO/CHANGELOG** - Automatyczna dokumentacja
- âœ… **Git Hooks** - Pre-commit/post-commit/pre-push
- âœ… **IDE Integration** - VS Code + Language Server Protocol  
- âœ… **Configuration Aggregation** - flake8, black, mypy, etc.
- âœ… **Execution Monitoring** - Åšledzenie bÅ‚Ä™dÃ³w i performancji
- âœ… **Quality Scoring** - Ocena jakoÅ›ci kodu 0-100
- âœ… **Task Prioritization** - Inteligentne priorytetyzowanie TODO

## ğŸ¤– **Ollama Integration - Gotowe do UÅ¼ycia**

### Quick Setup
```bash
# 1. Zainstaluj Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 2. Pobierz model dla kodu
ollama pull codellama:7b        # 4GB RAM
ollama pull codellama:13b       # 8GB RAM - zalecane
ollama pull phind-codellama:34b # 20GB RAM - najlepsze

# 3. Uruchom Ollama
ollama serve

# 4. Zainstaluj goLLM
./install.sh

# 5. Skonfiguruj
gollm config set llm_integration.enabled true
gollm config set llm_integration.providers.ollama.enabled true
gollm config set llm_integration.providers.ollama.model codellama:7b

# 6. Test
gollm generate "Create a user authentication function"
```

### Workflow z Ollama
```bash
# UÅ¼ytkownik prosi o kod
gollm generate "Create payment processor with error handling"

# â†“ goLLM wysyÅ‚a do Ollama z kontekstem:
# - ReguÅ‚y jakoÅ›ci projektu (max 50 linii, no prints, etc.)
# - Ostatnie bÅ‚Ä™dy i traceback
# - Zadania TODO do naprawy  
# - Standard kodowania zespoÅ‚u
# - Historia zmian w plikach

# â†“ Ollama generuje kod Python

# â†“ goLLM automatycznie waliduje:
# âŒ Naruszenia znalezione â†’ feedback do Ollama â†’ iteracja
# âœ… Kod OK â†’ zapis + aktualizacja TODO/CHANGELOG

# Rezultat: Wysokiej jakoÅ›ci kod zgodny ze standardami projektu
```

## ğŸ“Š **PorÃ³wnanie ProviderÃ³w LLM**

| Provider | Model | PrywatnoÅ›Ä‡ | Koszt | JakoÅ›Ä‡ | SzybkoÅ›Ä‡ | Offline |
|----------|-------|------------|-------|---------|----------|---------|
| **Ollama** | CodeLlama 7B | âœ… 100% | âœ… Darmowy | ğŸŸ¡ Dobra | ğŸŸ¡ Åšrednia | âœ… Tak |
| **Ollama** | CodeLlama 13B | âœ… 100% | âœ… Darmowy | âœ… Bardzo dobra | ğŸŸ¡ Åšrednia | âœ… Tak |
| **OpenAI** | GPT-4 | âŒ 0% | âŒ $0.03-0.12/1k | âœ… Najlepsza | âœ… Szybka | âŒ Nie |
| **Anthropic** | Claude-3 | âŒ 0% | âŒ $0.01-0.08/1k | âœ… Bardzo dobra | ğŸŸ¡ Åšrednia | âŒ Nie |

**Rekomendacja**: 
- **Ollama CodeLlama 13B** dla wiÄ™kszoÅ›ci projektÃ³w (prywatnoÅ›Ä‡ + jakoÅ›Ä‡)
- **OpenAI GPT-4** dla maksymalnej jakoÅ›ci (rozwiÄ…zania enterprise)

## ğŸ’¡ **Kluczowe Komendy**

```bash
# Podstawowe
gollm validate-project     # Waliduj caÅ‚y projekt
gollm status              # PokaÅ¼ status jakoÅ›ci
gollm next-task           # PokaÅ¼ nastÄ™pne zadanie TODO
gollm fix --auto          # Automatyczna naprawa problemÃ³w

# Integracja z LLM
gollm generate "zadanie"  # Generuj kod z pomocÄ… AI
gollm fix --llm plik.py  # Napraw kod z pomocÄ… AI

# WiÄ™cej informacji
gollm --help              # WyÅ›wietl dostÄ™pne komendy
```

> ğŸ“˜ PeÅ‚na dokumentacja dostÄ™pna w [przewodniku uÅ¼ytkownika](./docs/guides/getting_started.md) i [dokumentacji API](./docs/api/README.md).


```
curl -X POST http://localhost:11434/api/generate -d '{"model": "codellama:7b", "prompt": "Write a Python function that adds two numbers", "stream": false}'
```


```
curl -X POST http://192.168.188.108:8081/api/generate -d '{"model": "qwen2.5:7b", "prompt": "Write a Python function that adds two numbers", "stream": false}'

curl http://192.168.188.108:8081/api/tags | jq
curl -X POST http://192.168.188.108:8081/api/generate -d '{"model": "deepseek-coder:1.3b", "prompt": "Write a Python function that adds two numbers", "stream": false}'

curl -X POST http://192.168.188.108:8081/api/chat \
     -H 'Content-Type: application/json' \
     -d '{
       "model": "deepseek-coder:1.3b",
       "messages": [ {"role": "user", "content": "Write Animation in shell in Python"} ],
       "stream": false
     }' | jq

curl -X POST http://rock:8081/api/chat \
     -H 'Content-Type: application/json' \
     -d '{
       "model": "deepseek-coder:1.3b",
       "messages": [ {"role": "user", "content": "Write Hello World in Python"} ],
       "stream": false
     }' | jq
     
curl -X POST http://192.168.188.212:11434/api/chat \
     -H 'Content-Type: application/json' \
     -d '{
       "model": "mistral",
       "messages": [ {"role": "user", "content": "StwÃ³rz klasÄ™ uÅ¼ytkownika"} ],
       "stream": false
     }' | jq
          
gollm generate "Write Hello World in Python"
gollm -v generate "Write Hello World in Python"
gollm generate "Write Hello World in Python" --fast
gollm generate "StwÃ³rz klasÄ™ uÅ¼ytkownika"
gollm generate "StwÃ³rz klasÄ™ uÅ¼ytkownika" --adapter-type modular
```