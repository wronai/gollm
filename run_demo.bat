# run_demo.bat - Windows version
@echo off
setlocal enabledelayedexpansion

echo üöÄ goLLM - Go Learn, Lead, Master! Demo
echo ==============================================
echo.

REM Check if Python is installed
python --version >nul 2>&1
if errorlevel 1 (
    echo ‚ùå Python is required but not installed
    echo Please install Python 3.8+ from https://python.org
    pause
    exit /b 1
)

echo ‚úÖ Python found

REM Create virtual environment if it doesn't exist
if not exist "venv" (
    echo üì¶ Creating virtual environment...
    python -m venv venv
)

REM Activate virtual environment
echo üîß Activating virtual environment...
call venv\Scripts\activate.bat

REM Upgrade pip
echo ‚¨ÜÔ∏è  Upgrading pip...
python -m pip install --upgrade pip >nul 2>&1

REM Install goLLM
echo ‚¨áÔ∏è  Installing goLLM...
pip install -e . >nul 2>&1

if errorlevel 1 (
    echo ‚ùå goLLM installation failed
    pause
    exit /b 1
)

echo ‚úÖ goLLM installed successfully
echo.

echo üéØ goLLM Demo - Code Quality in Action
echo ======================================
echo.

echo 1Ô∏è‚É£  Validating BAD code example...
echo -----------------------------------
python -m gollm validate examples\bad_code.py
echo.

echo 2Ô∏è‚É£  Validating GOOD code example...
echo ------------------------------------
python -m gollm validate examples\good_code.py
echo.

echo 3Ô∏è‚É£  Project status overview...
echo ------------------------------
python -m gollm status
echo.

echo 4Ô∏è‚É£  Next TODO task...
echo --------------------
python -m gollm next-task
echo.

echo 5Ô∏è‚É£  Configuration display...
echo ---------------------------
if exist "examples\gollm.json" (
    type examples\gollm.json
) else (
    echo ‚ö†Ô∏è  Configuration file not found
)
echo.

echo 6Ô∏è‚É£  LLM Integration Status...
echo ----------------------------
echo ‚ÑπÔ∏è  LLM integration is available but requires setup:
echo.
echo   For Ollama (local, free):
echo     1. Download from ollama.ai
echo     2. Install and run: ollama pull codellama:7b
echo     3. Enable: gollm config set llm_integration.enabled true
echo.
echo   For OpenAI:
echo     1. Get API key from platform.openai.com
echo     2. Set environment variable: set OPENAI_API_KEY=sk-...
echo     3. Enable: gollm config set llm_integration.providers.openai.enabled true
echo.

echo üéâ Demo completed!
echo.
echo üí° Essential Commands:
echo    gollm validate-project    # Validate entire project
echo    gollm status             # Show project status
echo    gollm next-task          # Get next TODO task
echo    gollm fix --auto         # Auto-fix violations
echo    gollm generate "prompt"  # Generate code with LLM (after setup)
echo    gollm --help             # Show all commands
echo.
echo üìö Documentation:
echo    docs\getting_started.md   # Getting started guide
echo    docs\configuration.md     # Configuration reference  
echo    docs\llm_integration.md   # LLM setup and usage
echo    docs\ollama_setup.md      # Local LLM with Ollama
echo.
echo üöÄ To start using goLLM in your projects:
echo    1. cd your_python_project
echo    2. gollm init
echo    3. gollm install-hooks
echo    4. gollm setup-ide --editor=vscode
echo.
echo Happy coding with goLLM! üêç‚ú®

pause

# quick_test.sh - Quick functionality test
#!/bin/bash

echo "üß™ goLLM Quick Test"
echo "=================="

# Test basic functionality
echo "Testing basic validation..."
python -m gollm validate examples/bad_code.py > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "‚úÖ Validation command works"
else
    echo "‚ùå Validation command failed"
    exit 1
fi

# Test configuration loading
echo "Testing configuration..."
python -c "from gollm.config.config import GollmConfig; GollmConfig.load('examples/gollm.json')" > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "‚úÖ Configuration loading works"
else
    echo "‚ùå Configuration loading failed"
    exit 1
fi

# Test project status
echo "Testing project status..."
python -m gollm status > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "‚úÖ Status command works"
else
    echo "‚ùå Status command failed"
    exit 1
fi

echo ""
echo "üéâ All basic tests passed!"
echo "goLLM is ready to use!"

# demo_with_ollama.sh - Extended demo with Ollama
#!/bin/bash

echo "ü§ñ goLLM + Ollama Integration Demo"
echo "=================================="

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "‚ùå Ollama not found"
    echo ""
    echo "To install Ollama:"
    echo "  curl -fsSL https://ollama.ai/install.sh | sh"
    echo ""
    echo "Then run this demo again."
    exit 1
fi

echo "‚úÖ Ollama found"

# Check if Ollama is running
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "‚ùå Ollama service not running"
    echo ""
    echo "Please start Ollama:"
    echo "  ollama serve"
    echo ""
    echo "Then run this demo again."
    exit 1
fi

echo "‚úÖ Ollama service running"

# Check for available models
echo "üìã Available Ollama models:"
ollama list

# Check for CodeLlama
if ollama list | grep -q "codellama"; then
    echo "‚úÖ CodeLlama model found"
    
    # Configure goLLM to use Ollama
    echo "‚öôÔ∏è  Configuring goLLM for Ollama..."
    
    # Create temporary config with Ollama enabled
    cp examples/gollm.json gollm_ollama_demo.json
    
    # Enable LLM integration (would normally use gollm config commands)
    python -c "
import json
with open('gollm_ollama_demo.json', 'r') as f:
    config = json.load(f)
config['llm_integration']['enabled'] = True
config['llm_integration']['providers']['ollama']['enabled'] = True
with open('gollm_ollama_demo.json', 'w') as f:
    json.dump(config, f, indent=2)
"
    
    echo "ü§ñ Testing code generation with Ollama..."
    
    # Test code generation
    python -m gollm --config gollm_ollama_demo.json generate "Create a simple function to add two numbers with proper documentation"
    
    if [ $? -eq 0 ]; then
        echo "‚úÖ Ollama code generation successful!"
    else
        echo "‚ö†Ô∏è  Ollama code generation had issues (this is normal for first run)"
    fi
    
    # Cleanup
    rm -f gollm_ollama_demo.json
    
else
    echo "‚ùå No CodeLlama model found"
    echo ""
    echo "To install a model for code generation:"
    echo "  ollama pull codellama:7b        # 4GB RAM required"
    echo "  ollama pull codellama:13b       # 8GB RAM required"
    echo "  ollama pull phind-codellama:34b # 20GB RAM required"
    echo ""
    echo "Then run this demo again."
fi

echo ""
echo "üéâ Ollama demo completed!"