# run_demo.bat - Windows version
@echo off
setlocal enabledelayedexpansion

echo üöÄ SPYQ - Smart Python Quality Guardian Demo
echo ==============================================
echo.

REM Check if Python is installed
python --version >nul 2>&1
if errorlevel 1 (
    echo ‚ùå Python is required but not installed
    echo Please install Python 3.8+ from https://python.org
    pause
    exit /b 1
)

echo ‚úÖ Python found

REM Create virtual environment if it doesn't exist
if not exist "venv" (
    echo üì¶ Creating virtual environment...
    python -m venv venv
)

REM Activate virtual environment
echo üîß Activating virtual environment...
call venv\Scripts\activate.bat

REM Upgrade pip
echo ‚¨ÜÔ∏è  Upgrading pip...
python -m pip install --upgrade pip >nul 2>&1

REM Install SPYQ
echo ‚¨áÔ∏è  Installing SPYQ...
pip install -e . >nul 2>&1

if errorlevel 1 (
    echo ‚ùå SPYQ installation failed
    pause
    exit /b 1
)

echo ‚úÖ SPYQ installed successfully
echo.

echo üéØ SPYQ Demo - Code Quality in Action
echo ======================================
echo.

echo 1Ô∏è‚É£  Validating BAD code example...
echo -----------------------------------
python -m spyq validate examples\bad_code.py
echo.

echo 2Ô∏è‚É£  Validating GOOD code example...
echo ------------------------------------
python -m spyq validate examples\good_code.py
echo.

echo 3Ô∏è‚É£  Project status overview...
echo ------------------------------
python -m spyq status
echo.

echo 4Ô∏è‚É£  Next TODO task...
echo --------------------
python -m spyq next-task
echo.

echo 5Ô∏è‚É£  Configuration display...
echo ---------------------------
if exist "examples\spyq.json" (
    type examples\spyq.json
) else (
    echo ‚ö†Ô∏è  Configuration file not found
)
echo.

echo 6Ô∏è‚É£  LLM Integration Status...
echo ----------------------------
echo ‚ÑπÔ∏è  LLM integration is available but requires setup:
echo.
echo   For Ollama (local, free):
echo     1. Download from ollama.ai
echo     2. Install and run: ollama pull codellama:7b
echo     3. Enable: spyq config set llm_integration.enabled true
echo.
echo   For OpenAI:
echo     1. Get API key from platform.openai.com
echo     2. Set environment variable: set OPENAI_API_KEY=sk-...
echo     3. Enable: spyq config set llm_integration.providers.openai.enabled true
echo.

echo üéâ Demo completed!
echo.
echo üí° Essential Commands:
echo    spyq validate-project    # Validate entire project
echo    spyq status             # Show project status
echo    spyq next-task          # Get next TODO task
echo    spyq fix --auto         # Auto-fix violations
echo    spyq generate "prompt"  # Generate code with LLM (after setup)
echo    spyq --help             # Show all commands
echo.
echo üìö Documentation:
echo    docs\getting_started.md   # Getting started guide
echo    docs\configuration.md     # Configuration reference  
echo    docs\llm_integration.md   # LLM setup and usage
echo    docs\ollama_setup.md      # Local LLM with Ollama
echo.
echo üöÄ To start using SPYQ in your projects:
echo    1. cd your_python_project
echo    2. spyq init
echo    3. spyq install-hooks
echo    4. spyq setup-ide --editor=vscode
echo.
echo Happy coding with SPYQ! üêç‚ú®

pause

# quick_test.sh - Quick functionality test
#!/bin/bash

echo "üß™ SPYQ Quick Test"
echo "=================="

# Test basic functionality
echo "Testing basic validation..."
python -m spyq validate examples/bad_code.py > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "‚úÖ Validation command works"
else
    echo "‚ùå Validation command failed"
    exit 1
fi

# Test configuration loading
echo "Testing configuration..."
python -c "from spyq.config.config import SpyqConfig; SpyqConfig.load('examples/spyq.json')" > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "‚úÖ Configuration loading works"
else
    echo "‚ùå Configuration loading failed"
    exit 1
fi

# Test project status
echo "Testing project status..."
python -m spyq status > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "‚úÖ Status command works"
else
    echo "‚ùå Status command failed"
    exit 1
fi

echo ""
echo "üéâ All basic tests passed!"
echo "SPYQ is ready to use!"

# demo_with_ollama.sh - Extended demo with Ollama
#!/bin/bash

echo "ü§ñ SPYQ + Ollama Integration Demo"
echo "=================================="

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "‚ùå Ollama not found"
    echo ""
    echo "To install Ollama:"
    echo "  curl -fsSL https://ollama.ai/install.sh | sh"
    echo ""
    echo "Then run this demo again."
    exit 1
fi

echo "‚úÖ Ollama found"

# Check if Ollama is running
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "‚ùå Ollama service not running"
    echo ""
    echo "Please start Ollama:"
    echo "  ollama serve"
    echo ""
    echo "Then run this demo again."
    exit 1
fi

echo "‚úÖ Ollama service running"

# Check for available models
echo "üìã Available Ollama models:"
ollama list

# Check for CodeLlama
if ollama list | grep -q "codellama"; then
    echo "‚úÖ CodeLlama model found"
    
    # Configure SPYQ to use Ollama
    echo "‚öôÔ∏è  Configuring SPYQ for Ollama..."
    
    # Create temporary config with Ollama enabled
    cp examples/spyq.json spyq_ollama_demo.json
    
    # Enable LLM integration (would normally use spyq config commands)
    python -c "
import json
with open('spyq_ollama_demo.json', 'r') as f:
    config = json.load(f)
config['llm_integration']['enabled'] = True
config['llm_integration']['providers']['ollama']['enabled'] = True
with open('spyq_ollama_demo.json', 'w') as f:
    json.dump(config, f, indent=2)
"
    
    echo "ü§ñ Testing code generation with Ollama..."
    
    # Test code generation
    python -m spyq --config spyq_ollama_demo.json generate "Create a simple function to add two numbers with proper documentation"
    
    if [ $? -eq 0 ]; then
        echo "‚úÖ Ollama code generation successful!"
    else
        echo "‚ö†Ô∏è  Ollama code generation had issues (this is normal for first run)"
    fi
    
    # Cleanup
    rm -f spyq_ollama_demo.json
    
else
    echo "‚ùå No CodeLlama model found"
    echo ""
    echo "To install a model for code generation:"
    echo "  ollama pull codellama:7b        # 4GB RAM required"
    echo "  ollama pull codellama:13b       # 8GB RAM required"
    echo "  ollama pull phind-codellama:34b # 20GB RAM required"
    echo ""
    echo "Then run this demo again."
fi

echo ""
echo "üéâ Ollama demo completed!"